import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import re
import string
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

class SMSClassifier:
    def __init__(self, file_path):
        self.file_path = file_path
        self.df = None
        self.vectorizer = None
        self.model = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
    def load_and_clean_data(self):
        """Load the CSV file and clean the data"""
        # Load the data
        self.df = pd.read_csv(self.file_path, encoding='latin-1')
        
        # Display basic info
        print("Dataset Info:")
        print(f"Shape: {self.df.shape}")
        print(f"Columns: {self.df.columns.tolist()}")
        
        # Clean the data - keep only relevant columns
        self.df = self.df[['v1', 'v2']]
        self.df.columns = ['label', 'message']
        
        # Remove rows with missing values
        self.df = self.df.dropna()
        
        # Clean the label column
        self.df['label'] = self.df['label'].str.strip().str.lower()
        
        print(f"\nCleaned dataset shape: {self.df.shape}")
        print(f"Label distribution:\n{self.df['label'].value_counts()}")
        
        return self.df
    
    def preprocess_text(self, text):
        """Preprocess the text data"""
        if not isinstance(text, str):
            return ""
        
        # Convert to lowercase
        text = text.lower()
        
        # Remove special characters and digits
        text = re.sub(r'[^a-zA-Z\s]', '', text)
        
        # Remove extra whitespace
        text = ' '.join(text.split())
        
        return text
    
    def explore_data(self):
        """Explore the dataset with visualizations"""
        # Label distribution
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        label_counts = self.df['label'].value_counts()
        plt.pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%')
        plt.title('Message Type Distribution')
        
        # Message length analysis
        plt.subplot(1, 3, 2)
        self.df['message_length'] = self.df['message'].apply(len)
        sns.boxplot(x='label', y='message_length', data=self.df)
        plt.title('Message Length by Type')
        
        # Word count analysis
        plt.subplot(1, 3, 3)
        self.df['word_count'] = self.df['message'].apply(lambda x: len(x.split()))
        sns.boxplot(x='label', y='word_count', data=self.df)
        plt.title('Word Count by Type')
        
        plt.tight_layout()
        plt.show()
        
        # Display some sample messages
        print("\nSample Ham Messages:")
        ham_samples = self.df[self.df['label'] == 'ham']['message'].head(3)
        for i, msg in enumerate(ham_samples, 1):
            print(f"{i}. {msg[:100]}...")
        
        print("\nSample Spam Messages:")
        spam_samples = self.df[self.df['label'] == 'spam']['message'].head(3)
        for i, msg in enumerate(spam_samples, 1):
            print(f"{i}. {msg[:100]}...")
    
    def prepare_features(self):
        """Prepare features for modeling"""
        # Apply text preprocessing
        self.df['clean_message'] = self.df['message'].apply(self.preprocess_text)
        
        # Split the data
        X = self.df['clean_message']
        y = self.df['label']
        
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Create TF-IDF features
        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
        self.X_train_tfidf = self.vectorizer.fit_transform(self.X_train)
        self.X_test_tfidf = self.vectorizer.transform(self.X_test)
        
        print(f"Training set shape: {self.X_train_tfidf.shape}")
        print(f"Test set shape: {self.X_test_tfidf.shape}")
    
    def train_model(self, model_type='naive_bayes'):
        """Train the classification model"""
        if model_type == 'naive_bayes':
            self.model = MultinomialNB()
        elif model_type == 'logistic_regression':
            self.model = LogisticRegression(random_state=42)
        else:
            raise ValueError("Model type must be 'naive_bayes' or 'logistic_regression'")
        
        self.model.fit(self.X_train_tfidf, self.y_train)
        
        # Make predictions
        y_pred = self.model.predict(self.X_test_tfidf)
        
        # Evaluate model
        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"\n{model_type.replace('_', ' ').title()} Model Results:")
        print(f"Accuracy: {accuracy:.4f}")
        print("\nClassification Report:")
        print(classification_report(self.y_test, y_pred))
        
        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        cm = confusion_matrix(self.y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.show()
        
        return y_pred
    
    def analyze_features(self):
        """Analyze important features for classification"""
        if not hasattr(self.model, 'coef_'):
            print("Feature analysis only available for linear models")
            return
        
        feature_names = self.vectorizer.get_feature_names_out()
        coefficients = self.model.coef_[0]
        
        # Get top spam indicators
        spam_indices = np.argsort(coefficients)[-20:]
        spam_features = [feature_names[i] for i in spam_indices]
        spam_scores = [coefficients[i] for i in spam_indices]
        
        # Get top ham indicators
        ham_indices = np.argsort(coefficients)[:20]
        ham_features = [feature_names[i] for i in ham_indices]
        ham_scores = [coefficients[i] for i in ham_indices]
        
        print("Top Spam Indicators:")
        for feature, score in zip(spam_features[::-1], spam_scores[::-1]):
            print(f"  {feature}: {score:.4f}")
        
        print("\nTop Ham Indicators:")
        for feature, score in zip(ham_features, ham_scores):
            print(f"  {feature}: {score:.4f}")
    
    def predict_message(self, message):
        """Predict if a new message is spam or ham"""
        if self.model is None or self.vectorizer is None:
            print("Please train the model first!")
            return
        
        # Preprocess the message
        clean_message = self.preprocess_text(message)
        
        # Transform using the trained vectorizer
        message_tfidf = self.vectorizer.transform([clean_message])
        
        # Make prediction
        prediction = self.model.predict(message_tfidf)[0]
        probability = self.model.predict_proba(message_tfidf)[0]
        
        print(f"\nMessage: {message}")
        print(f"Prediction: {prediction}")
        print(f"Probability - Ham: {probability[0]:.4f}, Spam: {probability[1]:.4f}")
        
        return prediction, probability

def main():
    # Initialize the classifier
    sms_classifier = SMSClassifier('spam.csv')  # Replace with your file path
    
    # Load and clean data
    df = sms_classifier.load_and_clean_data()
    
    # Explore the data
    sms_classifier.explore_data()
    
    # Prepare features
    sms_classifier.prepare_features()
    
    # Train Naive Bayes model
    print("="*50)
    print("NAIVE BAYES MODEL")
    print("="*50)
    sms_classifier.train_model('naive_bayes')
    
    # Train Logistic Regression model
    print("="*50)
    print("LOGISTIC REGRESSION MODEL")
    print("="*50)
    sms_classifier.train_model('logistic_regression')
    
    # Analyze features (for logistic regression)
    sms_classifier.analyze_features()
    
    # Test with sample messages
    print("="*50)
    print("SAMPLE PREDICTIONS")
    print("="*50)
    
    test_messages = [
        "Congratulations! You've won a $1000 Walmart gift card. Click here to claim now!",
        "Hey, are we still meeting for lunch tomorrow?",
        "URGENT: Your bank account has been compromised. Call now to verify: 555-1234",
        "Ok, see you at home. Don't forget to buy milk"
    ]
    
    for msg in test_messages:
        sms_classifier.predict_message(msg)
        print("-" * 40)

if __name__ == "__main__":
    main()
